import pandas as pd
df=pd.read_csv(r"C:\Users\ASUS\Desktop\swati\Mall_Customers.csv")
df.head(10)
df.keys()

x=df[['Annual Income (k$)','Spending Score (1-100)']].values

import warnings
warnings.filterwarnings("ignore")

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
wcss=[]
for i in range(1,15):
    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)
    kmeans.fit(x)
    wcss.append(kmeans.inertia_)
plt.figure(figsize=(4,3))
plt.plot(range(1,15),wcss)
plt.xticks(range(1,15))
plt.show()

help(KMeans)

kmeans=KMeans(n_clusters=6,init='k-means++',random_state=42)
y_predict=kmeans.fit_predict(x)
yp=kmeans.fit_predict(x)

plt.scatter(x[y_predict == 0, 0], x[y_predict == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') #for first cluster  
plt.scatter(x[y_predict == 1, 0], x[y_predict == 1, 1], s = 100, c = 'green', label = 'Cluster 2') #for second cluster  
plt.scatter(x[y_predict== 2, 0], x[y_predict == 2, 1], s = 100, c = 'red', label = 'Cluster 3') #for third cluster  
plt.scatter(x[y_predict == 3, 0], x[y_predict == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') #for fourth cluster  
plt.scatter(x[y_predict == 4, 0], x[y_predict == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') #for fifth cluster  
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroid')   
plt.title('Clusters of customers')  
plt.xlabel('Annual Income (k$)')  
plt.ylabel('Spending Score (1-100)')  
plt.legend()  
plt.show() 

plt.scatter(x[yp==0,0],x[yp==0,1],s=100,c="blue",label="c1")
plt.scatter(x[yp==1,0],x[yp==1,1],s=100,c="yellow",label="c2")
plt.scatter(x[yp==2,0],x[yp==2,1],s=100,c="green",label="c3")
plt.scatter(x[yp==3,0],x[yp==3,1],s=100,c="pink",label="c4")
plt.scatter(x[yp==4,0],x[yp==4,1],s=100,c="black",label="c5")
plt.scatter(x[yp==5,0],x[yp==5,1],s=100,c="brown",label="c6")
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c="red",label="centroid")
plt.legend()
plt.show()


from sklearn.metrics import silhouette_score
print(silhouette_score(x,kmeans.labels_))

import scipy.cluster.hierarchy as sch
dendrogram = sch.dendrogram(sch.linkage(x, method='ward'))
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean Distances')
plt.show()

from sklearn.cluster import AgglomerativeClustering

agglomerative = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
y_agglomerative = agglomerative.fit_predict(x)

plt.scatter(x[y_agglomerative == 0, 0], x[y_agglomerative == 0, 1], s=100, c='blue', label='Cluster 1')
plt.scatter(x[y_agglomerative == 1, 0], x[y_agglomerative == 1, 1], s=100, c='green', label='Cluster 2')
plt.scatter(x[y_agglomerative == 2, 0], x[y_agglomerative == 2, 1], s=100, c='red', label='Cluster 3')
plt.scatter(x[y_agglomerative == 3, 0], x[y_agglomerative == 3, 1], s=100, c='pink', label='Cluster 4')
plt.scatter(x[y_agglomerative == 4, 0], x[y_agglomerative == 4, 1], s=100, c='yellow', label='Cluster 5')
plt.title('Agglomerative Clustering')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

from scipy.cluster.hierarchy import dendrogram, linkage, fcluster

Z = linkage(x, method='ward')
dendrogram(Z)
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean Distances')
plt.show()

num_clusters = 5
labels = fcluster(Z, t=num_clusters, criterion='maxclust')

plt.scatter(x[labels == 1, 0], x[labels == 1, 1], s=100, c='blue', label='Cluster 1')
plt.scatter(x[labels == 2, 0], x[labels == 2, 1], s=100, c='green', label='Cluster 2')
plt.scatter(x[labels == 3, 0], x[labels == 3, 1], s=100, c='red', label='Cluster 3')
plt.scatter(x[labels == 4, 0], x[labels == 4, 1], s=100, c='pink', label='Cluster 4')
plt.scatter(x[labels == 5, 0], x[labels == 5, 1], s=100, c='yellow', label='Cluster 5')
plt.title('Divisive Clustering')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()



import scipy.cluster.hierarchy as sch
den= sch.dendrogram(sch.linkage(x,method='ward'))
plt.show()

from scipy.cluster.hierarchy import dendrogram, linkage, fcluster

Z = linkage(x, method='ward')
num_clusters = 5
labels = fcluster(Z, t=num_clusters, criterion='maxclust')

plt.scatter(x[labels == 1, 0], x[labels == 1, 1], s=100, c='blue', label='Cluster 1')
plt.scatter(x[labels == 2, 0], x[labels == 2, 1], s=100, c='green', label='Cluster 2')
plt.scatter(x[labels == 3, 0], x[labels == 3, 1], s=100, c='red', label='Cluster 3')
plt.scatter(x[labels == 4, 0], x[labels == 4, 1], s=100, c='pink', label='Cluster 4')
plt.scatter(x[labels == 5, 0], x[labels == 5, 1], s=100, c='yellow', label='Cluster 5')
plt.title('Divisive Clustering')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()


from sklearn.cluster import AgglomerativeClustering
help(AgglomerativeClustering)

from scipy.cluster.hierarchy import dendrogram

from scipy.cluster.hierarchy import linkage

from scipy.cluster.hierarchy import fcluster
help(fcluster)

